{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, utils, models\n",
    "# from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import altair as alt\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Change csv name as needed\n",
    "labels_extended = pd.read_csv('data/selected_gene_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "SUBSET = False\n",
    "if SUBSET:\n",
    "    labels_extended = labels_extended.sample(frac=0.01, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "clean_possible_genes = labels_extended.columns.to_list()[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of trainset: (31083, 27)\n",
      "Shape of testset: (5486, 27)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(labels_extended, train_size=0.85, random_state=123)\n",
    "print(f'Shape of trainset: {train_df.shape}')\n",
    "print(f'Shape of testset: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 836, 856])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open(\"data/img/10000-0.png\")\n",
    "\n",
    "# Convert the image to a tensor\n",
    "transform_image = v2.ToImage()\n",
    "tensor_image = transform_image(image)\n",
    "tensor_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class PythonGeneDataset(Dataset):\n",
    "    def __init__(self, labels_df, img_dir, indices=None, transform=None):\n",
    "        self.labels_df = labels_df\n",
    "        if indices is not None:\n",
    "            self.labels_df = self.labels_df.iloc[indices]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, f\"{self.labels_df.iloc[idx, 0]}.png\")\n",
    "        image = Image.open(img_name)\n",
    "        # Parse labels here based on your CSV structure and required format\n",
    "        labels = torch.tensor(self.labels_df.iloc[idx, 7:].astype('float32').values)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to RAM\n",
    "class PythonGeneDataset(Dataset):\n",
    "    def __init__(self, labels_df, img_dir, transform=None):\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        \n",
    "        # Preload all images into memory\n",
    "        for idx in range(len(self.labels_df)):\n",
    "            img_path = os.path.join(img_dir, f\"{self.labels_df.iloc[idx, 0]}.png\")\n",
    "            image = Image.open(img_path).convert('RGB')  # Ensure image is RGB\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            # Store the preprocessed image\n",
    "            self.data.append(image)\n",
    "        \n",
    "        # Preconvert labels if they don't need to be augmented dynamically\n",
    "        self.labels = torch.tensor(self.labels_df.iloc[:, 7:].values.astype('float32'))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve preloaded and transformed image and labels\n",
    "        image = self.data[idx]\n",
    "        labels = self.labels[idx]\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 512\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True), # Normalize expects float input\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "full_dataset = PythonGeneDataset(labels_df=train_df, img_dir='data/img/', transform=transform)\n",
    "\n",
    "# Split dataset\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "valid_size = total_size - train_size\n",
    "train_indices, valid_indices = torch.utils.data.random_split(np.arange(total_size), [train_size, valid_size])\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "valid_dataset = Subset(full_dataset, valid_indices)\n",
    "\n",
    "# Initialize DataLoaders\n",
    "BATCH_SIZE = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=12)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PythonGeneClassifier(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(PythonGeneClassifier, self).__init__()\n",
    "#         # Increasing the complexity of the network\n",
    "#         self.feature_extractor = nn.Sequential(\n",
    "#             nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),\n",
    "#             nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),\n",
    "#             nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),\n",
    "#             nn.Dropout(0.25)  # Adding dropout for regularization\n",
    "#         )\n",
    "\n",
    "#         # Flatten layer is moved to the forward function\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(64 * 4 * 4, 512),  # Adjusted for 32x32 input images; calculate accordingly\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(512, num_classes)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.feature_extractor(x)\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "#         x = self.classifier(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning (DenseNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "densenet = models.densenet201(weights='DenseNet201_Weights.DEFAULT')\n",
    "\n",
    "for param in densenet.parameters():  # Freeze parameters so we don't update them\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1920, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1920, out_features=1000, bias=True)\n",
       "  (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=1000, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(clean_possible_genes)\n",
    "print(num_labels)\n",
    "\n",
    "new_layers = nn.Sequential(\n",
    "    nn.Linear(1920, 1000),  # Reduce dimension from 1024 to 500\n",
    "    nn.BatchNorm1d(1000),   # Normalize the activations from the previous layer\n",
    "    nn.ReLU(),             # Non-linear activation function\n",
    "    nn.Dropout(0.5),       # Dropout for regularization (50% probability)\n",
    "    nn.Linear(1000, num_labels)  # Final layer for class predictions\n",
    ")\n",
    "densenet.classifier = new_layers\n",
    "densenet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Implement focal loss for label imbalance\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # Prevents nans when probability is 0\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using: {device}')\n",
    "densenet.to(device)\n",
    "\n",
    "focal_loss = FocalLoss()\n",
    "criterion = focal_loss\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(densenet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, start_epoch, total_epochs, version=1, save_checkpoint=True):\n",
    "    \"\"\"\n",
    "    Train a model with specified criterion and optimizer. \n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The neural network model to be trained.\n",
    "    - criterion (torch.nn.Module): The loss function used for the training.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer used for parameter updates.\n",
    "    - start_epoch (int): The starting epoch number for training. Useful for resuming training. Set to 1 if starting from scratch.\n",
    "    - total_epochs (int): The total number of epochs to train the model for.\n",
    "    - version (int, optional): Version number of the model checkpoint files. Default is 1. Recommend to specify when save_checkpoint=True.\n",
    "    - save_checkpoint (bool, optional): Flag to control whether to save checkpoints after each epoch. Default is True.\n",
    "\n",
    "    Outputs:\n",
    "    - The function does not return any values but prints training and validation loss after each epoch and saves model checkpoints if specified.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    # Assuming criterion and optimizer are predefined, this will train the densenet model for 10 epochs, starting from epoch 21.\n",
    "    # This is useful when you have checkpoint models up until epoch 20.\n",
    "    # Checkpoints will be saved and named as version 2.\n",
    "    train_model(densenet, criterion, optimizer,\n",
    "            start_epoch=21,\n",
    "            total_epochs=30,\n",
    "            version=2,\n",
    "            save_checkpoint=True)\n",
    "    ```\n",
    "\n",
    "    Note:\n",
    "    - Ensure that the device (CPU or GPU) is appropriately set for the model, criterion, and data tensors.\n",
    "    - The global variables BATCH_SIZE, IMAGE_SIZE, train_loader, and valid_loader are used within this function and should be defined in the scope where this function is called.\n",
    "    \"\"\"\n",
    "    print(f'Start training - batch size: {BATCH_SIZE} & image size: {IMAGE_SIZE}')\n",
    "    \n",
    "    for epoch in range(start_epoch, total_epochs + 1):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            train_loss = 0.0\n",
    "            for inputs, labels in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch}/{total_epochs}\")\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate average loss for the epoch\n",
    "            train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "            # Validation of the model\n",
    "            model.eval()  # Set model to evaluate mode\n",
    "            valid_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in valid_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate average loss over validation data\n",
    "            valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "            # Checkpoint\n",
    "            if save_checkpoint:\n",
    "                CHECKPOINT_PATH = f'model/model_v{version}_epoch{epoch}.pt'\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'image_size': IMAGE_SIZE,\n",
    "                    'batch_size': BATCH_SIZE,\n",
    "                    'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss,\n",
    "                    }, CHECKPOINT_PATH)\n",
    "\n",
    "            # Print training/validation statistics\n",
    "            print(f'Epoch {epoch}/{total_epochs}, Train Loss: {train_loss:.5f}, Valid Loss: {valid_loss:.5f}')\n",
    "            tepoch.set_postfix(train_loss=train_loss,\n",
    "                               valid_loss=valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_epoch(LOAD_CHECKPOINT, num_additional_epochs, checkpoint_version, checkpoint_epoch):\n",
    "    if LOAD_CHECKPOINT:\n",
    "        checkpoint_path = f'model/model_v{checkpoint_version}_epoch{checkpoint_epoch}.pt'\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        print(f'Loaded version {checkpoint_version}-epoch {checkpoint_epoch}')\n",
    "\n",
    "        densenet.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint_epoch + 1\n",
    "        train_loss = checkpoint['train_loss']\n",
    "        valid_loss = checkpoint['valid_loss']\n",
    "\n",
    "        print(f'Checkpoint Train Loss: {train_loss:.5f} & Valid Loss: {valid_loss:.5f}')\n",
    "    else:\n",
    "        start_epoch = 1  # Start from scratch if not loading from checkpoint\n",
    "\n",
    "    total_epochs = start_epoch + num_additional_epochs - 1\n",
    "    return start_epoch, total_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded version 2-epoch 21\n",
      "Checkpoint Train Loss: 0.00805 & Valid Loss: 0.01170\n",
      "Starting at Epoch: 22, Ending at Epoch: 22\n"
     ]
    }
   ],
   "source": [
    "LOAD_CHECKPOINT = True\n",
    "checkpoint_version = 2\n",
    "checkpoint_epoch = 20\n",
    "num_additional_epochs = 1\n",
    "\n",
    "start_epoch, total_epochs = get_epoch(LOAD_CHECKPOINT, num_additional_epochs, checkpoint_version, checkpoint_epoch)\n",
    "print(f'Starting at Epoch: {start_epoch}, Ending at Epoch: {total_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training - batch size: 256 & image size: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:10<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdensenet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtotal_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43msave_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 40\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, start_epoch, total_epochs, version, save_checkpoint)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(train_loader, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tepoch:\n\u001b[1;32m     39\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtepoch\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtepoch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_description\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtotal_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/deep-learning/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/conda/envs/deep-learning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/envs/deep-learning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/deep-learning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/deep-learning/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/deep-learning/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/conda/envs/deep-learning/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/deep-learning/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/conda/envs/deep-learning/lib/python3.11/multiprocessing/connection.py:947\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    944\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 947\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/conda/envs/deep-learning/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(densenet, criterion, optimizer,\n",
    "            start_epoch=start_epoch,\n",
    "            total_epochs=total_epochs,\n",
    "            version=2,\n",
    "            save_checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PythonGeneClassifier(num_classes=len(clean_possible_genes))\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f'Training on {device}')\n",
    "# model.to(device)\n",
    "\n",
    "# summary(model, input_size=(3, IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trainer(model, criterion, optimizer, trainloader, validloader, epochs=20, patience=5, verbose=True):\n",
    "#     \"\"\"Simple training wrapper for PyTorch network.\"\"\"\n",
    "#     train_loss, valid_loss, valid_accuracy = [], [], []\n",
    "#     consec_increases = 0\n",
    "#     for epoch in range(epochs):  # for each epoch\n",
    "#         train_batch_loss = 0\n",
    "#         valid_batch_loss = 0\n",
    "#         valid_batch_acc = 0\n",
    "#         # Training\n",
    "#         for X, y in trainloader:\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             y_hat = model(X)\n",
    "#             loss = criterion(y_hat, y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             train_batch_loss += loss.item()\n",
    "#         train_loss.append(train_batch_loss / len(trainloader))\n",
    "#         # Validation\n",
    "#         with torch.no_grad():\n",
    "#             for X, y in validloader:\n",
    "#                 X, y = X.to(device), y.to(device)\n",
    "#                 y_hat = model(X)\n",
    "#                 loss = criterion(y_hat, y)\n",
    "#                 valid_batch_loss += loss.item()\n",
    "#                 _, predicted = torch.max(y_hat.data, 1)\n",
    "#                 valid_batch_acc += (predicted == y).sum().item() / y.size(0)\n",
    "#         valid_loss.append(valid_batch_loss / len(validloader))\n",
    "#         valid_accuracy.append(valid_batch_acc / len(validloader))  # accuracy\n",
    "#         model.train()\n",
    "#         # Print progress\n",
    "#         if verbose:\n",
    "#             print(f\"Epoch {epoch + 1}:\",\n",
    "#                   f\"Train Loss: {train_loss[-1]:.3f}.\",\n",
    "#                   f\"Valid Loss: {valid_loss[-1]:.3f}.\",\n",
    "#                   f\"Valid Accuracy: {valid_accuracy[-1]:.2f}.\")\n",
    "#         # Early stopping\n",
    "#         if epoch > 0 and valid_loss[-1] > valid_loss[-2]:\n",
    "#             consec_increases += 1\n",
    "#         else:\n",
    "#             consec_increases = 0\n",
    "#         if consec_increases == patience:\n",
    "#             print(f\"Stopped early at epoch {epoch + 1:3}: val loss increased for {consec_increases} consecutive epochs!\")\n",
    "#             break\n",
    "#     results = {\"train_loss\": train_loss, \"valid_loss\": valid_loss, \"valid_accuracy\": valid_accuracy}\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Prediction by image\u001b[39;00m\n\u001b[1;32m      2\u001b[0m img_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m22968-0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/img/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m input_img \u001b[38;5;241m=\u001b[39m transform(img)\n\u001b[1;32m      5\u001b[0m input_img \u001b[38;5;241m=\u001b[39m input_img\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# Prediction by image\n",
    "img_code = '22968-0'\n",
    "img = Image.open(f'data/img/{img_code}.png')\n",
    "input_img = transform(img)\n",
    "input_img = input_img.unsqueeze(0)\n",
    "input_img.shape\n",
    "\n",
    "# Load the checkpoint model\n",
    "densenet = models.densenet201(weights='DenseNet201_Weights.DEFAULT')\n",
    "densenet.classifier = new_layers\n",
    "optimizer = torch.optim.Adam(densenet.parameters(), lr=0.001)\n",
    "\n",
    "checkpoint = torch.load(f'model/model_v2_epoch20.pt')\n",
    "densenet.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "train_loss = checkpoint['train_loss']\n",
    "valid_loss = checkpoint['valid_loss']\n",
    "\n",
    "densenet.eval()\n",
    "\n",
    "# If using GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "densenet.to(device)\n",
    "input_img = input_img.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = densenet(input_img)\n",
    "\n",
    "predicted_probs = torch.sigmoid(output).to('cpu')\n",
    "prediction = pd.DataFrame(predicted_probs, index=['predictions'],\n",
    "                          columns=clean_possible_genes).T.sort_values(by=['predictions'], ascending=False)\n",
    "\n",
    "# True labels\n",
    "print(labels_extended.query(f'index == \"{img_code}\"').genes.to_list())\n",
    "\n",
    "prediction.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on Test set: 0.01181\n"
     ]
    }
   ],
   "source": [
    "# Loss on test set\n",
    "test_dataset = PythonGeneDataset(labels_df=test_df, img_dir='data/img/', transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "densenet.eval()  # Set model to evaluate mode\n",
    "\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = densenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "# Calculate average loss over validation data\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "print(f'Loss on Test set: {test_loss:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
