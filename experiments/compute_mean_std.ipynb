{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, utils, models, transforms\n",
    "# from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR, ExponentialLR\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import v2\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import altair as alt\n",
    "from tqdm import tqdm \n",
    "\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 30\n",
      "Shape of trainset: (41416, 37)\n"
     ]
    }
   ],
   "source": [
    "labels_extended = pd.read_csv('data/selected_gene_df.csv')\n",
    "\n",
    "clean_possible_genes = labels_extended.columns.to_list()[7:]\n",
    "print(f'Number of labels: {len(clean_possible_genes)}')\n",
    "\n",
    "train_df, test_df = train_test_split(labels_extended, train_size=0.85, random_state=123)\n",
    "print(f'Shape of trainset: {train_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PythonGeneDataset(Dataset):\n",
    "    def __init__(self, labels_df, img_dir, indices=None, transform=None):\n",
    "        self.labels_df = labels_df\n",
    "        if indices is not None:\n",
    "            self.labels_df = self.labels_df.iloc[indices]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, f\"{self.labels_df.iloc[idx, 0]}.png\")\n",
    "        image = Image.open(img_name)\n",
    "        labels = torch.tensor(self.labels_df.iloc[idx, 7:].astype('float32').values)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((480, 480)),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "    ])\n",
    "full_dataset = PythonGeneDataset(labels_df=train_df, img_dir='data/img/', transform=transform)\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "valid_size = total_size - train_size\n",
    "train_indices, valid_indices = torch.utils.data.random_split(np.arange(total_size), [train_size, valid_size])\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,\n",
    "                          num_workers=multiprocessing.cpu_count(), pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Mean and Std: 100%|██████████| 518/518 [12:20<00:00,  1.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  tensor([0.6007, 0.5679, 0.5206])\n",
      "Std:  tensor([0.2411, 0.2392, 0.2479])\n"
     ]
    }
   ],
   "source": [
    "mean = 0.\n",
    "std = 0.\n",
    "total_images_count = 0\n",
    "\n",
    "for images, _ in tqdm(train_loader, desc=\"Calculating Mean and Std\", unit=\"batch\"):\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.var(2).sum(0)\n",
    "    total_images_count += batch_samples\n",
    "\n",
    "mean /= total_images_count\n",
    "std = torch.sqrt(std / total_images_count)\n",
    "\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Std: \", std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
